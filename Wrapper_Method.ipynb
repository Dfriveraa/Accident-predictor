{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing # LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler # Escala los datos\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scikitplot as skplt \n",
    "from string import ascii_uppercase \n",
    "# import seaborn as sns\n",
    "import qgrid\n",
    "import time\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from scipy import stats #Para la moda\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('CSV ready to model/withoutPCA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "df['GRAVEDAD']=df.loc[:,['GRAVEDAD']].apply(le.fit_transform)\n",
    "y=df['GRAVEDAD']\n",
    "x=df.drop(['GRAVEDAD','PERIODO'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(modelo, n_features, fwd, fltg):\n",
    "\n",
    "    sfs = SFS(modelo, \n",
    "           k_features=n_features,\n",
    "           forward=fwd,\n",
    "           floating=fltg,\n",
    "           verbose=0,\n",
    "           scoring='accuracy',\n",
    "           cv=0,\n",
    "           n_jobs=-1)\n",
    "    \n",
    "    return sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classification_error(y_est, y_real):\n",
    "    err = 0\n",
    "    for y_e, y_r in zip(y_est, y_real):\n",
    "\n",
    "        if y_e != y_r:\n",
    "            err += 1\n",
    "\n",
    "    return err/np.size(y_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(X,Y,features):\n",
    "    print(features)\n",
    "    fwd = True\n",
    "    fltg = True\n",
    "        \n",
    "    #Para calcular el costo computacional\n",
    "    tiempo_i = time.time()\n",
    "\n",
    "    accuracy_list = np.zeros([4])\n",
    "    precision_list = np.zeros([4,3])\n",
    "    recall_list = np.zeros([4,3])\n",
    "    f_list = np.zeros([4,3])\n",
    "    \n",
    "    feature_list = [] #Para guardar los indices de las características que eligió en cada iteración\n",
    "    XN_list = [] #Para guardar los diferentes X\n",
    "    sf_list = []\n",
    "    #model = RandomForestClassifier(n_estimators=100, max_features =2, n_jobs = -1)\n",
    "    #Implemetamos la metodología de validación \n",
    "#     model = svm.SVC(decision_function_shape='ovo', kernel='rbf', C = 10, gamma = 1,n_jobs=-1)\n",
    "    model = AdaBoostClassifier(n_estimators=50)\n",
    "\n",
    "    Errores = np.ones(4)\n",
    "    \n",
    "    for j in range(4):\n",
    "\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.25) # Modificar metodología de validación\n",
    "        sf = select_features(model, features, fwd, fltg)\n",
    "        sf =  sf.fit(Xtrain, Ytrain)\n",
    "\n",
    "        X_train_sfs = sf.transform(Xtrain)\n",
    "        X_test_sfs = sf.transform(Xtest)\n",
    "        XN = sf.transform(X)\n",
    "\n",
    "        model.fit(X_train_sfs, Ytrain)\n",
    "        pred = model.predict(X_test_sfs)\n",
    "        \n",
    "        #code for calculating accuracy \n",
    "        _accuracy_ = accuracy_score(Ytest, pred, normalize=True)\n",
    "        accuracy_list[j] = _accuracy_\n",
    "\n",
    "        #code for calculating recall \n",
    "        _recalls_ = recall_score(Ytest, pred, average=None)\n",
    "        recall_list[j] = _recalls_\n",
    "\n",
    "        #code for calculating precision \n",
    "        _precisions_ = precision_score(Ytest, pred, average=None)\n",
    "        precision_list[j] = _precisions_\n",
    "        \n",
    "        _f_score_ = f1_score(Ytest, pred, average=None)\n",
    "        f_list[j] = _f_score_\n",
    "\n",
    "        Errores[j] = classification_error(pred, Ytest)\n",
    "        \n",
    "        feature_list.extend(sf.k_feature_idx_)\n",
    "        \n",
    "        XN_list.append(XN)\n",
    "        sf_list.append(sf)\n",
    "    \n",
    "    \n",
    "    index = np.where(accuracy_list == np.amax(accuracy_list)) #Busca cual es el resultado más grande en la lista de accuracy(eficiencia)   \n",
    "    idx = index[0][0] #pasa el índice de array a entero   \n",
    "    XN = XN_list[idx] #Selecciona el mejor X \n",
    "    sf = sf_list[idx] #índices de las mejores características\n",
    "    \n",
    "    result={'xn':XN,'features':sf,'Eficiencia':np.mean(accuracy_list),'Int_Eficiencia':np.std(accuracy_list),\n",
    "    'Sensibilidad':np.mean(recall_list),'Int_Sensibilidad':np.std(recall_list),\n",
    "    'Precisión':np.mean(precision_list),'Int Precisión':np.std(precision_list),\n",
    "    'F':np.mean(f_list),'Int_F':np.std(f_list),\n",
    "    'Error':np.mean(Errores),'Int_Error':np.std(Errores),\n",
    "    'Tiempo':time.time()-tiempo_i\n",
    "    }\n",
    "    return  result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "(1, 4)\n",
      "3\n",
      "3\n",
      "(1, 4, 6)\n",
      "4\n",
      "4\n",
      "(1, 3, 4, 6)\n",
      "5\n",
      "5\n",
      "(1, 2, 3, 4, 6)\n",
      "6\n",
      "6\n",
      "(0, 2, 3, 5, 6, 8)\n",
      "7\n",
      "7\n",
      "(0, 2, 3, 4, 5, 6, 7)\n",
      "8\n",
      "8\n",
      "(0, 1, 2, 3, 4, 6, 7, 8)\n",
      "9\n",
      "9\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8)\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({'# de características seleccionadas' : pd.Series([2,3,4,5,6,7,8,9])})\n",
    "df_types[\"Eficiencia\"] = \"\"\n",
    "df_types[\"Int_Eficiencia\"] = \"\"\n",
    "df_types[\"Sensibilidad\"] = \"\"\n",
    "df_types[\"Int_Sensibilidad\"] = \"\"\n",
    "df_types[\"Precision\"] = \"\"\n",
    "df_types[\"Int_Precision\"] = \"\"\n",
    "df_types[\"F-Score\"] = \"\"\n",
    "df_types[\"Int_F-Score\"] = \"\"\n",
    "df_types[\"Error_Prueba\"] = \"\"\n",
    "df_types[\"Int_error\"] = \"\"\n",
    "df_types[\"Tiempo de ejecución\"] = \"\"\n",
    "df_types.set_index(['# de características seleccionadas'], inplace=True)\n",
    "\n",
    "for k in df_types.index:\n",
    "    result= selection(x,y,k)\n",
    "    print(k)\n",
    "    print(result['features'].k_feature_idx_)\n",
    "\n",
    "    df_types[\"Eficiencia\"][k] = result['Eficiencia']\n",
    "    df_types[\"Int_Eficiencia\"][k] = result['Int_Eficiencia']\n",
    "    df_types[\"Sensibilidad\"][k] = result['Sensibilidad']\n",
    "    df_types[\"Int_Sensibilidad\"][k] = result['Int_Sensibilidad']\n",
    "    df_types[\"Precision\"][k] = result['Precisión']\n",
    "    df_types[\"Int_Precision\"][k] = result['Precisión']\n",
    "    df_types[\"F-Score\"][k] = result['F']\n",
    "    df_types[\"Int_F-Score\"][k] = result['Int_F']\n",
    "    df_types[\"Error_Prueba\"][k] = result['Error']\n",
    "    df_types[\"Int_error\"][k] = result['Int_Error']\n",
    "    df_types[\"Tiempo de ejecución\"][k] = result['Tiempo']\n",
    "    \n",
    "qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fa463ba34e448bae92c312a3a72afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1)standar scaler 8 caracteristicas\n",
    "2)min max 8 caracteristicas\n",
    "3)standar scaler 9 caracteristicas\n",
    "4)min max 9 caracteristicas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Accident-predictor)",
   "language": "python",
   "name": "pycharm-a42563eb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
